{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d643620e",
   "metadata": {},
   "source": [
    "#### Types of reasoning agents\n",
    "1.Function Calling Agents - These work with AI models that can call specific functions.\n",
    "2. ReAct Agents - These can work with any AI that does chat or text endpoint and deal with complex reasoning tasks.\n",
    "3. Advanced Custom Agents - These use more complex methods to deal with more complex tasks and workflows.\n",
    "\n",
    "to create an agent we start by providing set of functions/tools thet define its capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e316e630",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mutaician/AIEngineerLearning/HuggingFaceAgentsCourse/llamaindex/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.llms.openrouter import OpenRouter\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENROUTER_API_KEY = os.environ.get(\"OPENROUTER_API_KEY\")\n",
    "if not OPENROUTER_API_KEY:\n",
    "    raise ValueError(\"OPENROUTER_API_KEY not found in environment variables. Please check your .env file.\")\n",
    "\n",
    "GOOGLE_API_KEY = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "if not GOOGLE_API_KEY:\n",
    "     print(\"Warning: GOOGLE_API_KEY not found. Google Embedding might fail if not using ADC.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ba5bf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent.workflow import AgentWorkflow, ToolCallResult, AgentStream\n",
    "\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "def subtract(a: int, b: int) -> int:\n",
    "    \"\"\"Subtract two numbers\"\"\"\n",
    "    return a - b\n",
    "\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "def divide(a: int, b: int) -> int:\n",
    "    \"\"\"Divide two numbers\"\"\"\n",
    "    return a / b\n",
    "\n",
    "\n",
    "llm = OpenRouter(\n",
    "    api_key=OPENROUTER_API_KEY,\n",
    "    max_tokens=256,\n",
    "    model=\"openrouter/optimus-alpha\"\n",
    ")\n",
    "\n",
    "agent = AgentWorkflow.from_tools_or_functions(\n",
    "    tools_or_functions=[subtract, multiply, divide, add],\n",
    "    llm=llm,\n",
    "    system_prompt=\"You are a math agent that can add, subtract, multiply, and divide numbers using provided tools.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f98369ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: add\n",
      "Action Input: {\"a\": 2, \"b\": 2}\n",
      "Called tool:  add {'a': 2, 'b': 2} => 4\n",
      "Thought: I have calculated 2+2=4. Now I need to multiply this result by 2.\n",
      "Action: multiply\n",
      "Action Input: {\"a\": 4, \"b\": 2}\n",
      "Called tool:  multiply {'a': 4, 'b': 2} => 8\n",
      "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: (2+2) * 2 = 8"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentOutput(response=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='(2+2) * 2 = 8')]), tool_calls=[ToolCallResult(tool_name='add', tool_kwargs={'a': 2, 'b': 2}, tool_id='c5319615-80c4-4306-8407-99fe667389e0', tool_output=ToolOutput(content='4', tool_name='add', raw_input={'args': (), 'kwargs': {'a': 2, 'b': 2}}, raw_output=4, is_error=False), return_direct=False), ToolCallResult(tool_name='multiply', tool_kwargs={'a': 4, 'b': 2}, tool_id='d0006982-3f22-49d5-9577-e5bdea5c40db', tool_output=ToolOutput(content='8', tool_name='multiply', raw_input={'args': (), 'kwargs': {'a': 4, 'b': 2}}, raw_output=8, is_error=False), return_direct=False)], raw={'id': 'gen-1744484790-XBZazbaMcuiZtI76Lez0', 'choices': [{'delta': {'content': '', 'function_call': None, 'refusal': None, 'role': 'assistant', 'tool_calls': None}, 'finish_reason': None, 'index': 0, 'logprobs': None, 'native_finish_reason': None}], 'created': 1744484790, 'model': 'openrouter/optimus-alpha', 'object': 'chat.completion.chunk', 'service_tier': None, 'system_fingerprint': None, 'usage': {'completion_tokens': 33, 'prompt_tokens': 842, 'total_tokens': 875, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'provider': 'Stealth'}, current_agent_name='Agent')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the agent and get the response and reasoning behind the tool calls\n",
    "handler = agent.run(\"What is (2+2) * 2?\")\n",
    "async for ev in handler.stream_events():\n",
    "    if isinstance(ev, ToolCallResult):\n",
    "        print(\"\")\n",
    "        print(\"Called tool: \", ev.tool_name, ev.tool_kwargs, \"=>\", ev.tool_output)\n",
    "    elif isinstance(ev, AgentStream):\n",
    "        print(ev.delta, end=\"\", flush=True)\n",
    "\n",
    "response = await handler\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c122e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentOutput(response=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='Sure! The name Cyprian has ancient roots and is derived from the Latin name \"Cyprianus,\" which means \"from Cyprus.\" It was popularized by Saint Cyprian, a notable early Christian bishop and writer from Carthage. The name is unique and carries a sense of history and distinction. It\\'s not very common, which makes it even cooler!')]), tool_calls=[], raw={'id': 'gen-1744485355-xjsE3enCRIFino2SlIKZ', 'choices': [{'delta': {'content': '', 'function_call': None, 'refusal': None, 'role': 'assistant', 'tool_calls': None}, 'finish_reason': None, 'index': 0, 'logprobs': None, 'native_finish_reason': None}], 'created': 1744485355, 'model': 'openrouter/optimus-alpha', 'object': 'chat.completion.chunk', 'service_tier': None, 'system_fingerprint': None, 'usage': {'completion_tokens': 98, 'prompt_tokens': 784, 'total_tokens': 882, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'provider': 'Stealth'}, current_agent_name='Agent')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass state and context to the agent\n",
    "from llama_index.core.workflow import Context\n",
    "\n",
    "ctx = Context(agent)\n",
    "response = await agent.run(\"My name is Cyprian.\", ctx=ctx)\n",
    "response = await agent.run(\"Could you tell me something cool about my name\", ctx=ctx)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "600bc223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load, index and store data \n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "reader = SimpleDirectoryReader(input_dir=\"data\")\n",
    "documents = reader.load_data()\n",
    "len(documents)\n",
    "\n",
    "from llama_index.embeddings.google_genai import GoogleGenAIEmbedding\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "import chromadb\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "\n",
    "db = chromadb.PersistentClient(path=\"./alfred_chroma_db\")\n",
    "chroma_collection = db.get_or_create_collection(name=\"alfred\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        SentenceSplitter(),\n",
    "        GoogleGenAIEmbedding(model_name=\"text-embedding-004\", api_key=GOOGLE_API_KEY)\n",
    "    ],\n",
    "    vector_store=vector_store,\n",
    ")\n",
    "\n",
    "nodes = await pipeline.arun(documents=documents[:100])\n",
    "len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e92b9210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG Agents with QueryEngineTools\n",
    "\n",
    "import chromadb\n",
    "\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.embeddings.google_genai import GoogleGenAIEmbedding\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "\n",
    "# Create a vector store\n",
    "db = chromadb.PersistentClient(path=\"./alfred_chroma_db\")\n",
    "chroma_collection = db.get_or_create_collection(\"alfred\")\n",
    "vector_store = ChromaVectorStore(chroma_collection)\n",
    "\n",
    "# Create query engine\n",
    "embed_model = GoogleGenAIEmbedding(api_key=GOOGLE_API_KEY)\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store=vector_store, embed_model=embed_model\n",
    ")\n",
    "query_engine = index.as_query_engine(llm=llm)\n",
    "query_engine_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=query_engine,\n",
    "    name=\"personas\",\n",
    "    description=\"descriptions for various types of personas\",\n",
    "    return_direct=False,\n",
    ")\n",
    "\n",
    "# Create a RAG agent\n",
    "query_engine_agent = AgentWorkflow.from_tools_or_functions(\n",
    "    tools_or_functions=[query_engine_tool],\n",
    "    llm=llm,\n",
    "    system_prompt=\"You are a helpful assistant that has access to a database containing persona descriptions. \",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b08a148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: personas\n",
      "Action Input: {\"input\": \"science fiction\"}\n",
      "Called tool:  personas {'input': 'science fiction'} => Science fiction is a genre that often explores imaginative concepts related to science and technology, such as space exploration, advanced neuroscience, or psychological phenomena. It can draw inspiration from fields like planetary geology, especially research on planets like Mars, and from psychological and neuroscientific discoveries, weaving them into stories that speculate about the future or alternate realities.\n",
      "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: Here are some persona descriptions related to 'science fiction':\n",
      "\n",
      "1. The Futurist Scientist: A visionary researcher who speculates about the future of technology, space travel, and human evolution. They are inspired by real scientific advancements and enjoy imagining how these could shape society.\n",
      "\n",
      "2. The Space Explorer: An adventurous astronaut or pilot, often driven by curiosity and a desire to discover new worlds. They are knowledgeable about planetary geology and the challenges of interstellar travel.\n",
      "\n",
      "3. The AI Ethicist: A thinker focused on the implications of artificial intelligence and robotics. They ponder questions about consciousness, ethics, and the relationship between humans and machines.\n",
      "\n",
      "4. The Alien Anthropologist: A specialist in studying extraterrestrial cultures and life forms, blending knowledge of psychology, neuroscience, and sociology to understand non-human perspectives.\n",
      "\n",
      "5. The Dystopian Survivor: Someone navigating a future society shaped by technological or environmental catastrophe. They are resourceful, skeptical, and often question the role of science in shaping their world.\n",
      "\n",
      "If you need more detailed persona descriptions or specific examples, let me know!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentOutput(response=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text=\"Here are some persona descriptions related to 'science fiction':\\n\\n1. The Futurist Scientist: A visionary researcher who speculates about the future of technology, space travel, and human evolution. They are inspired by real scientific advancements and enjoy imagining how these could shape society.\\n\\n2. The Space Explorer: An adventurous astronaut or pilot, often driven by curiosity and a desire to discover new worlds. They are knowledgeable about planetary geology and the challenges of interstellar travel.\\n\\n3. The AI Ethicist: A thinker focused on the implications of artificial intelligence and robotics. They ponder questions about consciousness, ethics, and the relationship between humans and machines.\\n\\n4. The Alien Anthropologist: A specialist in studying extraterrestrial cultures and life forms, blending knowledge of psychology, neuroscience, and sociology to understand non-human perspectives.\\n\\n5. The Dystopian Survivor: Someone navigating a future society shaped by technological or environmental catastrophe. They are resourceful, skeptical, and often question the role of science in shaping their world.\\n\\nIf you need more detailed persona descriptions or specific examples, let me know!\")]), tool_calls=[ToolCallResult(tool_name='personas', tool_kwargs={'input': 'science fiction'}, tool_id='66e3f60c-6270-460c-a5e2-37765c62a0aa', tool_output=ToolOutput(content='Science fiction is a genre that often explores imaginative concepts related to science and technology, such as space exploration, advanced neuroscience, or psychological phenomena. It can draw inspiration from fields like planetary geology, especially research on planets like Mars, and from psychological and neuroscientific discoveries, weaving them into stories that speculate about the future or alternate realities.', tool_name='personas', raw_input={'input': 'science fiction'}, raw_output=Response(response='Science fiction is a genre that often explores imaginative concepts related to science and technology, such as space exploration, advanced neuroscience, or psychological phenomena. It can draw inspiration from fields like planetary geology, especially research on planets like Mars, and from psychological and neuroscientific discoveries, weaving them into stories that speculate about the future or alternate realities.', source_nodes=[NodeWithScore(node=TextNode(id_='810214b7-2469-4b6a-950d-2156bd3d2699', embedding=None, metadata={'file_path': '/home/mutaician/AIEngineerLearning/HuggingFaceAgentsCourse/llamaindex/data/persona_1053.txt', 'file_name': 'persona_1053.txt', 'file_type': 'text/plain', 'file_size': 145, 'creation_date': '2025-04-12', 'last_modified_date': '2025-04-12'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='805eb532-942f-49cc-8483-1df01f9ca4a1', node_type='4', metadata={'file_path': '/home/mutaician/AIEngineerLearning/HuggingFaceAgentsCourse/llamaindex/data/persona_1053.txt', 'file_name': 'persona_1053.txt', 'file_type': 'text/plain', 'file_size': 145, 'creation_date': '2025-04-12', 'last_modified_date': '2025-04-12'}, hash='cd19c2e2e24c33c58009c4b73ef5e8634785ad75afc99e8db04b7144cfa96c6b')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='A science writer or journalist focused on psychology and neuroscience, possibly writing for a popular audience or a general-interest publication.', mimetype='text/plain', start_char_idx=0, end_char_idx=145, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.33140436165889847), NodeWithScore(node=TextNode(id_='8efcb658-59c9-42b4-97b3-5e21e873b29a', embedding=None, metadata={'file_path': '/home/mutaician/AIEngineerLearning/HuggingFaceAgentsCourse/llamaindex/data/persona_1009.txt', 'file_name': 'persona_1009.txt', 'file_type': 'text/plain', 'file_size': 172, 'creation_date': '2025-04-12', 'last_modified_date': '2025-04-12'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='5604dc15-b4b8-4244-af3e-163a729dec20', node_type='4', metadata={'file_path': '/home/mutaician/AIEngineerLearning/HuggingFaceAgentsCourse/llamaindex/data/persona_1009.txt', 'file_name': 'persona_1009.txt', 'file_type': 'text/plain', 'file_size': 172, 'creation_date': '2025-04-12', 'last_modified_date': '2025-04-12'}, hash='312100a15068009d766c6dda9bc83db6977378b7a75d1d42dfc812addc27b336')}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"A planetary geologist focused on Martian research and exploration, specifically studying the planet's subsurface composition and its implications for future human missions.\", mimetype='text/plain', start_char_idx=0, end_char_idx=172, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.32280471349630874)], metadata={'810214b7-2469-4b6a-950d-2156bd3d2699': {'file_path': '/home/mutaician/AIEngineerLearning/HuggingFaceAgentsCourse/llamaindex/data/persona_1053.txt', 'file_name': 'persona_1053.txt', 'file_type': 'text/plain', 'file_size': 145, 'creation_date': '2025-04-12', 'last_modified_date': '2025-04-12'}, '8efcb658-59c9-42b4-97b3-5e21e873b29a': {'file_path': '/home/mutaician/AIEngineerLearning/HuggingFaceAgentsCourse/llamaindex/data/persona_1009.txt', 'file_name': 'persona_1009.txt', 'file_type': 'text/plain', 'file_size': 172, 'creation_date': '2025-04-12', 'last_modified_date': '2025-04-12'}}), is_error=False), return_direct=False)], raw={'id': 'gen-1744489071-g9EoOvBhZdYJ0O26g7PG', 'choices': [{'delta': {'content': '', 'function_call': None, 'refusal': None, 'role': 'assistant', 'tool_calls': None}, 'finish_reason': None, 'index': 0, 'logprobs': None, 'native_finish_reason': None}], 'created': 1744489071, 'model': 'openrouter/optimus-alpha', 'object': 'chat.completion.chunk', 'service_tier': None, 'system_fingerprint': None, 'usage': {'completion_tokens': 237, 'prompt_tokens': 587, 'total_tokens': 824, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'provider': 'Stealth'}, current_agent_name='Agent')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handler = query_engine_agent.run(\n",
    "    \"Search the database for 'science fiction' and return some persona descriptions.\"\n",
    ")\n",
    "async for ev in handler.stream_events():\n",
    "    if isinstance(ev, ToolCallResult):\n",
    "        print(\"\")\n",
    "        print(\"Called tool: \", ev.tool_name, ev.tool_kwargs, \"=>\", ev.tool_output)\n",
    "    elif isinstance(ev, AgentStream):  # showing the thought process\n",
    "        print(ev.delta, end=\"\", flush=True)\n",
    "\n",
    "resp = await handler\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5747d2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiagent systems\n",
    "from llama_index.core.agent.workflow import (\n",
    "    AgentWorkflow,\n",
    "    ReActAgent,\n",
    ")\n",
    "\n",
    "\n",
    "# Define some tools\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "def subtract(a: int, b: int) -> int:\n",
    "    \"\"\"Subtract two numbers.\"\"\"\n",
    "    return a - b\n",
    "\n",
    "\n",
    "# Create agent configs\n",
    "# NOTE: we can use FunctionAgent or ReActAgent here.\n",
    "# FunctionAgent works for LLMs with a function calling API.\n",
    "# ReActAgent works for any LLM.\n",
    "calculator_agent = ReActAgent(\n",
    "    name=\"calculator\",\n",
    "    description=\"Performs basic arithmetic operations\",\n",
    "    system_prompt=\"You are a calculator assistant. Use your tools for any math operation.\",\n",
    "    tools=[add, subtract],\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "query_agent = ReActAgent(\n",
    "    name=\"info_lookup\",\n",
    "    description=\"Looks up information about XYZ\",\n",
    "    system_prompt=\"Use your tool to query a RAG system to answer information about XYZ\",\n",
    "    tools=[query_engine_tool],\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "# Create and run the workflow\n",
    "agent = AgentWorkflow(agents=[calculator_agent, query_agent], root_agent=\"calculator\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2402a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: The current language of the user is English. I need to use a tool to add 5 and 3.\n",
      "Action: add\n",
      "Action Input: {\"a\": 5, \"b\": 3}\n",
      "Called tool:  add {'a': 5, 'b': 3} => 8\n",
      "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: The sum of 5 and 3 is 8."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentOutput(response=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='The sum of 5 and 3 is 8.')]), tool_calls=[ToolCallResult(tool_name='add', tool_kwargs={'a': 5, 'b': 3}, tool_id='93386e74-d476-4f0d-8fac-3c45e7b4ecb2', tool_output=ToolOutput(content='8', tool_name='add', raw_input={'args': (), 'kwargs': {'a': 5, 'b': 3}}, raw_output=8, is_error=False), return_direct=False)], raw={'id': 'gen-1744489263-OdNx19T74sLSxoUCGn7R', 'choices': [{'delta': {'content': '', 'function_call': None, 'refusal': None, 'role': 'assistant', 'tool_calls': None}, 'finish_reason': None, 'index': 0, 'logprobs': None, 'native_finish_reason': None}], 'created': 1744489263, 'model': 'openrouter/optimus-alpha', 'object': 'chat.completion.chunk', 'service_tier': None, 'system_fingerprint': None, 'usage': {'completion_tokens': 34, 'prompt_tokens': 750, 'total_tokens': 784, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'provider': 'Stealth'}, current_agent_name='calculator')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the system\n",
    "handler = agent.run(user_msg=\"Can you add 5 and 3?\")\n",
    "async for ev in handler.stream_events():\n",
    "    if isinstance(ev, ToolCallResult):\n",
    "        print(\"\")\n",
    "        print(\"Called tool: \", ev.tool_name, ev.tool_kwargs, \"=>\", ev.tool_output)\n",
    "    elif isinstance(ev, AgentStream):  # showing the thought process\n",
    "        print(ev.delta, end=\"\", flush=True)\n",
    "\n",
    "resp = await handler\n",
    "resp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
